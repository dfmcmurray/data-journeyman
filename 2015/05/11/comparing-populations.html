<!DOCTYPE html><html><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge,chrome=1"><title>Comparing Populations</title><meta name=viewport content="width=device-width"><link rel=stylesheet href=//maxcdn.bootstrapcdn.com/bootstrap/3.2.0/css/bootstrap.min.css><link rel=stylesheet href=/css/main.6763.css></head><body><div class=site><div id=header><a href="/"><div class=title></div><!-- <img class="title" src="/img/title-anglecia.0948.png" /> --><!-- <div class='title'>
			Data Journeyman
		</div>	 --><!-- <div class='tagline'>
			One man's journey from noise to knowledge<img src="/img/datum.e49d.png" />
		</div> --></a></div><div class=post-container><div class=post-heading><h2>Comparing Populations</h2><p class=meta>11 May 2015</p><div class=tags><span class="tag Curriculum">Curriculum</span> <span class="tag Inferential Stats">Inferential Stats</span> <span class="tag Statistics">Statistics</span> <span class="tag Video">Video</span></div></div><div class=post><h3 id=mean-and-variance-of-sums-of-random-variables>Mean and Variance of Sums of Random Variables</h3><p>Given two independent random variables, X and Y, let’s define a new random variable, Z, which is defined as follows:</p><p>\[Z = X + Y\]</p><p>What do we know about the mean and variance of Z?</p><p>We can figure out the mean of Z simply by the rules of expected values.</p><p>\[\mu_z = E[Z] = E[X + Y] = E[X] + E[Y] = \mu_x + \mu_y\]</p><p>So we have the mean of Z is just the mean of X plus the mean of Y. This makes sense because, on average, the values for X will center around \(\mu_x\) and the values for Y will center around \(\mu_y\) and both variable are <em>independent</em> of each other. The fact that they’re independent means that, given enough samples of Z, the variation of X away from its mean won’t have any influence on the variation of Y away from its mean, and values of Z will be centered around \(\mu_x + \mu_y\).</p><p>The variance for Z can be figured out by using <a href=http://www.datajourneyman.com/2015/03/09/correlation.html>its expected value definition</a> as well.</p><p>\[ \begin{eqnarray} \sigma_z^2 &amp;=&amp; E[Z^2] - (E[Z])^2\cr &amp;=&amp; E[(X + Y)^2] - (E[X + Y])^2\cr &amp;=&amp; E[X^2 + 2XY + Y^2] - ((E[X])^2 + 2E[X]E[Y] + (E[Y])^2)\cr &amp;=&amp; E[X^2] + 2E[X]E[Y] + E[Y^2] - (E[X])^2 - 2E[X]E[Y] - (E[Y])^2\cr &amp;=&amp; E[X^2] - (E[X])^2 + E[Y^2] - (E[Y])^2\cr &amp;=&amp; \sigma_x^2 + \sigma_y^2 \end{eqnarray} \]</p><p>This result is less intuitive, but the idea that as either the variance of X or the variance of Y increases (or as both variances increase), the resulting variance of Z will increase with it.</p><h3 id=mean-and-variance-of-differences-of-random-variables>Mean and Variance of Differences of Random Variables</h3><p>Now, using the same independent random variables, X and Y, let’s define Z to be their difference.</p><p>\[Z = X - Y\]</p><p>Calculating the mean works the same way as before.</p><p>\[\mu_z = E[Z] = E[X - Y] = E[X] - E[Y] = \mu_x - \mu_y\]</p><p>For the same reasons as before, this result makes sense.</p><p>The variance, however, doesn’t quite follow the same pattern.</p><p>\[ \begin{eqnarray} \sigma_z^2 &amp;=&amp; E[Z^2] - (E[Z])^2\cr &amp;=&amp; E[(X - Y)^2] - (E[X - Y])^2\cr &amp;=&amp; E[X^2 - 2XY + Y^2] - ((E[X])^2 - 2E[X]E[Y] + (E[Y])^2)\cr &amp;=&amp; E[X^2] - 2E[X]E[Y] + E[Y^2] - (E[X])^2 + 2E[X]E[Y] - (E[Y])^2\cr &amp;=&amp; E[X^2] - (E[X])^2 + E[Y^2] - (E[Y])^2\cr &amp;=&amp; \sigma_x^2 + \sigma_y^2 \end{eqnarray} \]</p><p>So when looking at the difference of two random variables, the variance is still the sum of each individual random variable’s variance. This actually does make sense, though, because if you have two independent random variables, their variances will not cancel each other out, just like we reasoned earlier. Otherwise, they would have a bias toward non-independence.</p><h3 id=mean-and-variance-of-differences-of-sampling-means-distributions>Mean and Variance of Differences of Sampling Means Distributions</h3><p>Now let’s look at how to calculate the mean and variance of Z where X and Y are not just any distribution, but a <a href=http://www.datajourneyman.com/2015/03/16/inferential-statistics.html>sampling distribution of the sampling mean</a>. Given X has a mean and variance of \(\mu_x\) and \(\sigma_x^2\), and Y has a mean and variance of \(\mu_y\) and \(\sigma_y^2\), and given a large enough sample sizes (n and m, respectively), we’ve seen the following to be true.</p><p>\[ \begin{eqnarray} \mu_{\bar x} = \mu_X, &amp; &amp; &amp; \sigma_{\bar x}^2 = \frac{\sigma_x^2}{n}\cr \mu_{\bar y} = \mu_Y, &amp; &amp; &amp; \sigma_{\bar y}^2 = \frac{\sigma_y^2}{m} \end{eqnarray} \]</p><p>So, define Z to be \(\bar X - \bar Y\).</p><p>\[ \begin{eqnarray} \mu_z &amp;=&amp; \mu_{\bar x} - \mu_{\bar y} &amp;=&amp; \mu_x - \mu_y\cr \sigma_z^2 &amp;=&amp; \sigma_{\bar x}^2 - \sigma_{\bar y}^2 &amp;=&amp; \frac{\sigma_x^2}{n} + \frac{\sigma_y^2}{m} \end{eqnarray} \]</p><h3 id=using-these-concepts-in-practice>Using These Concepts in Practice</h3><p>In previous posts, when we did exercises on <a href=http://www.datajourneyman.com/2015/04/06/confidence-intervals.html>confidence intervals</a> and <a href=http://www.datajourneyman.com/2015/04/13/hypothesis-testing.html>hypothesis testing</a>, we compared a sample to the true parameters of the overall population. But oftentimes, you are interested in the differences (or lack thereof) between two samples. For instance, if you poll 100 US Democrats and 100 US Republicans, you will need these methods to determine if the two groups statistically differ in their answers.</p><p>In the Inferential Statistics section of Khan Academy that we’ve been following, Sal covers both <a href=https://www.khanacademy.org/math/probability/statistics-inferential/hypothesis-testing-two-samples/v/confidence-interval-of-difference-of-means>confidence intervals</a> and <a href=https://www.khanacademy.org/math/probability/statistics-inferential/hypothesis-testing-two-samples/v/hypothesis-test-for-difference-of-means>hypothesis testing</a>. He then goes on to give examples of the Bernouli Distribution specifically in this context. The examples are worth a watch to see how these techniques in this post are used in practice.</p></div><div class=comments><div id=disqus_thread></div><script type=text/javascript>/* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
	        var disqus_shortname = 'datajourneyman'; // required: replace example with your forum shortname

	        /* * * DON'T EDIT BELOW THIS LINE * * */
	        (function() {
	            var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
	            dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
	            (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
	        })();</script><noscript>Please enable JavaScript to view the <a href=http://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript><a href=http://disqus.com class=dsq-brlink>comments powered by <span class=logo-disqus>Disqus</span></a></div></div></div><script src=//ajax.googleapis.com/ajax/libs/jquery/2.1.1/jquery.min.js></script><script src=//maxcdn.bootstrapcdn.com/bootstrap/3.2.0/js/bootstrap.min.js></script><script src=//cdn.blockspring.com/blockspring.js></script><script src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">MathJax.Hub.Config({
		"HTML-CSS": { linebreaks: { automatic: true } },
		SVG: { linebreaks: { automatic: true } },
		TeX: { 
            Macros: { 
              goodbreak: '\\mmlToken{mo}[linebreak="goodbreak"]{}', 
              badbreak: ['\\mmlToken{mo}[linebreak="badbreak"]{#1}',1], 
              nobreak: ['\\mmlToken{mo}[linebreak="nobreak"]{#1}',1], 
              invisibletimes: ['\\mmlToken{mo}{\u2062}'] 
            } 
        } 
    });</script><script src=/js/scripts.08ae.js></script><script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-10466691-5', 'auto');
  ga('send', 'pageview');</script></body></html>